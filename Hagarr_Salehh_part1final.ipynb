{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fe70a65",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'LinAlgFunctions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mLinAlgFunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'LinAlgFunctions'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from LinAlgFunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd8760d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[ 0.5       , -0.09090909, -0.09090909, -0.04545455, -0.10606061],\n",
    "       [-0.09090909,  0.18181818,  0.01515152,  0.        , -0.01515152],\n",
    "       [-0.09090909,  0.01515152,  0.31818182,  0.09090909, -0.01515152],\n",
    "       [-0.04545455,  0.        ,  0.09090909,  0.34090909, -0.09090909],\n",
    "       [-0.10606061, -0.01515152, -0.01515152, -0.09090909,  0.34090909]])\n",
    "\n",
    "# Create exact solution and vector b\n",
    "x_exact = np.ones(5)\n",
    "b = A@x_exact\n",
    "\n",
    "# Create Identity matrix\n",
    "I = np.eye(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c251b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3877787807814457e-16\n"
     ]
    }
   ],
   "source": [
    "# Compute Cholesky decomposition\n",
    "\n",
    "\n",
    "def Cholesky(A):\n",
    "    n = A.shape[0] # Get the number of rows (or columns) of the square matrix A\n",
    "    L = np.zeros_like(A) # Initialize an empty lower triangular matrix L\n",
    "    \n",
    "    for k in range(n):\n",
    "        # Compute the diagonal element of L at position (k, k)\n",
    "        L[k, k] = np.sqrt(A[k, k] - np.dot(L[k, :k], L[k, :k]))\n",
    "        for i in range(k + 1, n):\n",
    "            L[i, k] = (A[i, k] - np.dot(L[i, :k], L[k, :k])) / L[k, k]\n",
    "    \n",
    "    return L  # Return the computed lower triangular matrix L\n",
    "# Perform the Cholesky decomposition\n",
    "# The function will decompose a given symmetric positive definite matrix A into L such that A = L @ L.T\n",
    "L=Cholesky(A)\n",
    "# Check if the Cholesky decomposition is correct by verifying ||L @ L.T - A|| (should be near zero)\n",
    "# This step calculates the infinity norm of the difference between L @ L.T and A\n",
    "\n",
    "# Check if the Cholesky decomposition it correct (norm should be near zero)\n",
    "print(np.linalg.norm(L@L.T - A, np.inf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cce7cb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.860316562520647e-17\n"
     ]
    }
   ],
   "source": [
    "# Compute inverse of matrix L\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def InvertL(L):\n",
    "    n = L.shape[0] # Get the size of the square matrix L\n",
    "    L_inv = np.zeros_like(L) # Initialize an empty matrix for the inverse\n",
    "\n",
    "    for k in range(n):\n",
    "        # Compute the diagonal element of the inverse (1 / L[k, k])\n",
    "        L_inv[k, k] = 1. / L[k, k]\n",
    "        for i in range(k + 1, n):\n",
    "            # Compute the off-diagonal elements of the inverse\n",
    "            # L_inv[i, k] = -(sum of L[i, k:i] * L_inv[k:i, k]) / L[i, i]\n",
    "            L_inv[i, k] = -(L[i,k:i]@L_inv[k:i,k])/L[i,i]\n",
    "    \n",
    "   \n",
    "    return L_inv\n",
    "    # Compute the inverse of L using the InvertL function\n",
    "Linv = InvertL(L)\n",
    "\n",
    "# Check if the inversion is correct by verifying ||L @ Linv - I|| (should be near zero)\n",
    "# This step calculates the infinity norm of the difference between L @ Linv and the identity matrix I\n",
    "# Check if inversion is correct (norm should be near zero)\n",
    "print(np.linalg.norm(L@Linv - I, np.inf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05a8e1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3306690738754696e-16\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def PLU(A):\n",
    "   \n",
    "    N = A.shape[0]  # Get the size of the square matrix A\n",
    "    P = np.eye(N)  # Initialize the permutation matrix as an identity matrix\n",
    "    L = np.eye(N)  # Initialize the lower triangular matrix as an identity matrix\n",
    "    U = A.copy()   # Copy A to perform row operations without altering the original matrix\n",
    "\n",
    "    for i in range(N):\n",
    "        # Find the row with the maximum pivot element in the current column (partial pivoting)\n",
    "        r_max = np.argmax(np.abs(U[i:, i])) + i\n",
    "\n",
    "        # Swap rows in U and update P and L accordingly\n",
    "        if r_max != i:\n",
    "            U[[i, r_max], :] = U[[r_max, i], :]  # Swap rows in U\n",
    "            P[[i, r_max], :] = P[[r_max, i], :]  # Swap rows in P\n",
    "            if i > 0:\n",
    "                L[[i, r_max], :i] = L[[r_max, i], :i]  # Adjust L for swapped rows\n",
    "\n",
    "        # Eliminate entries below the pivot element\n",
    "        for j in range(i + 1, N):\n",
    "            factor = U[j, i] / U[i, i]  # Compute the elimination factor\n",
    "            L[j, i] = factor            # Store the factor in L\n",
    "            U[j, i:] -= factor * U[i, i:]  # Update the row in U to make entries below the pivot zero\n",
    "\n",
    "    return P, L, U\n",
    "\n",
    "\n",
    "def forward(L, b):\n",
    "   \n",
    "    y = np.zeros_like(b)  # Initialize solution vector y with zeros\n",
    "    for i in range(len(b)):\n",
    "        # Compute each element of y sequentially, using previously computed values\n",
    "        y[i] = (b[i] - np.dot(L[i, :i], y[:i])) / L[i, i]\n",
    "    return y\n",
    "\n",
    "\n",
    "def backward(U, y):\n",
    "   \n",
    "    N = len(y)  # Get the size of the vector\n",
    "    x = np.zeros_like(y)  # Initialize solution vector x with zeros\n",
    "    for i in range(N-1, -1, -1):  # Work backwards from the last row to the first\n",
    "        # Compute each element of x sequentially, using already computed values\n",
    "        sum_Ux = np.dot(U[i, i+1:], x[i+1:])  # Sum up the contributions of already computed x values\n",
    "        x[i] = (y[i] - sum_Ux) / U[i, i]  # Solve for the current variable\n",
    "    return x\n",
    "\n",
    "\n",
    "def PLUSolve(A, b):\n",
    "    \n",
    "    P, L, U = PLU(A)  # Perform PLU decomposition\n",
    "    b_n = np.dot(P, b)  # Apply the permutation matrix to b\n",
    "    y = forward(L, b_n)  # Solve Ly = b_n using forward substitution\n",
    "    x = backward(U, y)  # Solve Ux = y using backward substitution\n",
    "    return x\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "x = PLUSolve(A, b)  # Solve Ax = b using PLUSolve\n",
    "\n",
    "# Check the solution accuracy by comparing with the exact solution\n",
    "print(np.linalg.norm(x - x_exact, np.inf))  # Norm should be near zero for an accurate solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9aed83dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Check vector 2-norm\n",
    "def vector_2norm(x):\n",
    "  return np.sqrt(np.sum(x**2))\n",
    "print(np.linalg.norm(x_exact, 2) - vector_2norm(x_exact))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f284d9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Check matrix infinity-norm\n",
    "def matrix_inf_norm(A):\n",
    "    abs_A = np.abs(A)\n",
    "    row_sums = np.sum(abs_A, axis=1) #sum each row \n",
    "    return np.max(row_sums) #return the max row after summation \n",
    "    \n",
    "print(np.linalg.norm(A, np.inf) - matrix_inf_norm(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa8500da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Check inner product\n",
    "def inner_product(x, y):\n",
    "    return np.sum(x * y)  #< x, y >\n",
    "print(np.inner(x_exact, b) - inner_product(x_exact, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d380f799-fccf-4c9c-b4e2-7f2d5aca4580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.585295799541611\n"
     ]
    }
   ],
   "source": [
    "# Check Neumann series computation\n",
    "# Get the size of the matrix A (assuming square matrix)\n",
    "def NeumannSeries(A, w=1):\n",
    "    N = A.shape[0]\n",
    "    D = np.diag(np.diag(A)) # D is the diagonal part of A\n",
    "    L = np.tril(A, -1)# L is the strictly lower triangular part of A\n",
    "    U = np.triu(A, 1)  # U is the strictly upper triangular part of A\n",
    "    M = D + w * L # M is D + w * L, a combination of diagonal and lower triangular parts\n",
    "    B = np.eye(N) - M / np.max(np.abs(M))\n",
    "    # Use a Neumann series to approximate M^{-1}\n",
    "    Minv = np.eye(N) # Minv starts as an identity matrix, which we will update iteratively\n",
    "    while matrix_inf_norm(np.eye(N) - (Minv/np.max(M))@M) > 1e-12:\n",
    "        Minv = np.eye(N) + B @ Minv\n",
    "    Minv /= np.max(np.abs(M))\n",
    "    return Minv\n",
    "w = 1\n",
    "B = NeumannSeries(A) # Call the NeumannSeries function to compute the inverse approximation\n",
    "# Check that the computed inverse is correct by comparing with the exact inverse\n",
    "# The norm should be close to zero if the approximation is good\n",
    "# Check that inverse was computed correctly (norm should be near zero)\n",
    "print(np.linalg.norm(B - np.linalg.inv(I - A), np.inf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ee28b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.149701404835952e-07\n"
     ]
    }
   ],
   "source": [
    "def Jacobi(A, b):\n",
    "    # Dinv is the inverse of the diagonal elements of A (element-wise inverse)\n",
    "    Dinv = 1 / np.diag(A)\n",
    "    \n",
    "    # L is the strictly lower triangular part of A\n",
    "    L = np.tril(A, k=-1)\n",
    "    \n",
    "    # U is the strictly upper triangular part of A\n",
    "    U = np.triu(A, k=1)\n",
    "    \n",
    "    # M is the combination of L and U (A = D + M)\n",
    "    M = L + U\n",
    "    \n",
    "    # Initial guess for the solution (u) is a zero vector\n",
    "    u = np.zeros_like(b)\n",
    "    \n",
    "    # Residual vector (r) is the difference between b and A @ u\n",
    "    r = b - A @ u\n",
    "    \n",
    "    # Initialize the array to store the relative residuals for each iteration\n",
    "    Jacobi = np.array([])\n",
    "    \n",
    "    # Iterate until the relative residual is sufficiently small\n",
    "    while vector_2norm(r) / vector_2norm(b) > 1e-6:\n",
    "        # Update the solution approximation u using Jacobi method formula\n",
    "        u = Dinv * (b - M @ u)\n",
    "        \n",
    "        # Update the residual vector r\n",
    "        r = b - A @ u\n",
    "        \n",
    "        # Store the relative residual in Jacobi for convergence monitoring\n",
    "        Jacobi = np.append(Jacobi, vector_2norm(r) / vector_2norm(b))\n",
    "    \n",
    "    # Return the computed solution vector u\n",
    "    return u\n",
    "\n",
    "x = Jacobi(A, b)  # Solve for x using the Jacobi method\n",
    "\n",
    "# Check the solution by comparing the computed solution to the exact solution\n",
    "# The norm should be close to zero if the approximation is accurate\n",
    "print(np.linalg.norm(x - x_exact, np.inf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "240f6cb9-ec4a-4c3d-84ce-29c91579f8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5870106868406424e-07\n"
     ]
    }
   ],
   "source": [
    "def GaussSeidel(A, b):\n",
    "    \n",
    "    N = A.shape[0]  # Get the size of the matrix A\n",
    "    \n",
    "    # Extract the diagonal of A\n",
    "    D = np.diag(np.diag(A))  \n",
    "    \n",
    "    # Extract the strictly lower triangular part of A\n",
    "    L = np.tril(A, -1)\n",
    "    \n",
    "    # Compute Minv, an approximate inverse of M = D + L, using the Neumann Series\n",
    "    Minv = NeumannSeries(A)\n",
    "    \n",
    "    # Extract the strictly upper triangular part of A\n",
    "    U = np.triu(A, 1)\n",
    "    \n",
    "    # Define M as the sum of the diagonal and lower triangular parts\n",
    "    M = D + L\n",
    "    \n",
    "    # Initialize the solution vector with zeros\n",
    "    u = np.zeros((N,))\n",
    "    \n",
    "    # Compute the initial residual (difference between b and Ax)\n",
    "    r = b - A @ u\n",
    "    \n",
    "    # Array to track the relative residuals for each iteration\n",
    "    Gauss = np.array([])\n",
    "    \n",
    "    # Iterate until the relative residual is below the tolerance threshold\n",
    "    while vector_2norm(r) / vector_2norm(b) > 1e-6:\n",
    "        # Update the solution vector using the Gauss-Seidel formula\n",
    "        u = Minv @ (b - U @ u)\n",
    "        \n",
    "        # Recompute the residual vector\n",
    "        r = b - A @ u\n",
    "        \n",
    "        # Store the relative residual for convergence tracking\n",
    "        Gauss = np.append(Gauss, vector_2norm(r) / vector_2norm(b))\n",
    "    \n",
    "    return u\n",
    "\n",
    "# Example usage:\n",
    "x = GaussSeidel(A, b)  # Solve Ax = b using Gauss-Seidel\n",
    "\n",
    "# Check the solution accuracy by comparing with the exact solution\n",
    "# The norm should be near zero for a correct solution\n",
    "print(np.linalg.norm(x - x_exact, np.inf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6dc797da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.654470455138892e-07\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to compute the infinity norm of a matrix\n",
    "def matrix_inf_norm(A):\n",
    "    return np.max(np.sum(np.abs(A), axis=1))\n",
    "\n",
    "# Function to compute the 2-norm of a vector\n",
    "def vector_2norm(x):\n",
    "    return np.sqrt(np.sum(x**2))\n",
    "\n",
    "# Define SOR function\n",
    "def SOR(A, b, w):\n",
    "    N = A.shape[0]\n",
    "    D = np.diag(np.diag(A))\n",
    "    L = np.tril(A, -1)\n",
    "    U = np.triu(A, 1)\n",
    "    M = D + w * L\n",
    "    B = np.eye(N) - M / np.max(M)\n",
    "\n",
    "    # Use a Neumann series to approximate M^{-1}\n",
    "    Minv = np.eye(N)\n",
    "    while matrix_inf_norm(np.eye(N) - (Minv / np.max(M)) @ M) > 1e-12:\n",
    "        Minv = np.eye(N) + B @ Minv\n",
    "    Minv /= np.max(M)\n",
    "    n= A.shape[0]\n",
    "    u = np.zeros(n)\n",
    "    r = b - A @ u\n",
    "    residuals = []\n",
    "\n",
    "    # Implement SOR iterations\n",
    "    while vector_2norm(r) / vector_2norm(b) > 1e-6:\n",
    "        u = Minv @ (w * (b - U @ u) + (1. - w) * D @ u)\n",
    "        r = b - A @ u\n",
    "        residuals.append(vector_2norm(r) / vector_2norm(b))\n",
    "\n",
    "    return u\n",
    "\n",
    "\n",
    "\n",
    "# Set relaxation parameter w\n",
    "w = 1.2  # Change this value as needed\n",
    "\n",
    "# Solve Ax = b using SOR\n",
    "x = SOR(A, b, w)\n",
    "\n",
    "\n",
    "# Check the solution (norm should be near zero)\n",
    "print(np.linalg.norm(x - x_exact, np.inf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4d2f099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3306690738754696e-16\n"
     ]
    }
   ],
   "source": [
    "# Solve Ax=b using conjugate gradient\n",
    "def CG(A, b):\n",
    "    N = A.shape[0]\n",
    "    u = np.zeros((N,))\n",
    "    r = b - A @ u\n",
    "    delta = inner_product(r, r)\n",
    "    bdelta = inner_product(b, b)\n",
    "    p = r\n",
    "    CG_residuals = np.array([])\n",
    "    while delta > bdelta * (1e-6)**2:\n",
    "        s = A @ p\n",
    "        alpha = delta / inner_product(p, s)\n",
    "        u = u + alpha * p\n",
    "        r = r - alpha * s\n",
    "        delta_new = inner_product(r, r)\n",
    "        p = r + (delta_new / delta) * p\n",
    "        delta = delta_new\n",
    "\n",
    "        CG_residuals = np.append(CG_residuals, vector_2norm(r) / vector_2norm(b))\n",
    "\n",
    "    return u\n",
    "\n",
    "# Assuming A, b, and x_exact are defined\n",
    "x = CG(A, b)\n",
    "\n",
    "# Check solution (norm should be near zero)\n",
    "print(np.linalg.norm(x - x_exact, np.inf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b5a1615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.440892098500626e-16\n"
     ]
    }
   ],
   "source": [
    "# Solve Ax=b using preconditioned conjugate gradient. PCG will call incomplete Cholesky.\n",
    "\n",
    "\n",
    "# Incomplete Cholesky Decomposition Function\n",
    "def IncompleteCholesky(A):\n",
    "    \n",
    "    n = A.shape[0]\n",
    "    L = np.zeros_like(A)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1):\n",
    "            if i == j:\n",
    "                # Compute the diagonal entries of L\n",
    "                L[i, j] = np.sqrt(A[i, i] - np.sum(L[i, :j] ** 2))\n",
    "            else:\n",
    "                # Compute the off-diagonal entries of L\n",
    "                L[i, j] = (A[i, j] - np.sum(L[i, :j] * L[j, :j])) / L[j, j]\n",
    "    \n",
    "    return L\n",
    "\n",
    "# Preconditioned Conjugate Gradient (PCG) Method\n",
    "def PCG(A, b, P=None):\n",
    "   \n",
    "    n = A.shape[0]\n",
    "    x = np.zeros(n)  # Initial guess for x\n",
    "    r = b - A @ x  # Initial residual\n",
    "    if P is None:\n",
    "        # Compute preconditioner using incomplete Cholesky decomposition\n",
    "        L = IncompleteCholesky(A)\n",
    "        P = np.linalg.inv(L @ L.T)  # Compute the approximate inverse of the preconditioner\n",
    "    z = P @ r  # Apply the preconditioner\n",
    "    p = z  # Initialize the conjugate direction\n",
    "    rs_old = np.dot(r, z)  # Initial value of r^T z\n",
    "\n",
    "    for _ in range(n):\n",
    "        Ap = A @ p  # Matrix-vector product\n",
    "        alpha = rs_old / np.dot(p, Ap)  # Compute step size\n",
    "        x = x + alpha * p  # Update solution\n",
    "        r = r - alpha * Ap  # Update residual\n",
    "        \n",
    "        # Check for convergence (norm of residual close to zero)\n",
    "        if np.linalg.norm(r) < 1e-6:\n",
    "            break\n",
    "        \n",
    "        z = P @ r  # Apply the preconditioner\n",
    "        rs_new = np.dot(r, z)  # Compute new r^T z\n",
    "        p = z + (rs_new / rs_old) * p  # Update conjugate direction\n",
    "        rs_old = rs_new  # Update rs_old for the next iteration\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "# Solve Ax = b using PCG\n",
    "x = PCG(A, b)\n",
    "\n",
    "\n",
    "\n",
    "# Check solution (norm should be near zero)\n",
    "print(np.linalg.norm(x - x_exact, np.inf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
